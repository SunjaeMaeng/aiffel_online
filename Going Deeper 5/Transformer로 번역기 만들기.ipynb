{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69a7e98",
   "metadata": {},
   "source": [
    "# 번역기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd92006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook \n",
    "from tqdm.notebook import tqdm    # Process 과정을 보기 위해\n",
    "\n",
    "import random\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72878f1",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8439aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME') + '/aiffel/transformer/data'\n",
    "kor_path = data_dir + \"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir + \"/korean-english-park.train.en\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e069a8",
   "metadata": {},
   "source": [
    "## 데이터 정제 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ca2760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94123\n",
      "78968\n"
     ]
    }
   ],
   "source": [
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "    print(len(kor))\n",
    "    cleaned_corpus = set([k + '\\t' + e for k, e in zip(kor, eng)])\n",
    "    print(len(cleaned_corpus))\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "063e882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence): \n",
    "    '''\n",
    "    모든 입력을 소문자로 변환합니다.\n",
    "    알파벳, 문장부호, 한글만 남기고 모두 제거합니다.\n",
    "    문장부호 양옆에 공백을 추가합니다.\n",
    "    문장 앞뒤의 불필요한 공백을 제거합니다.\n",
    "    '''\n",
    "    entence = sentence.lower()\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣?.!,]+\", \" \", sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24b933c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=corpus_ko.txt --pad_id=0 --bos_id=1 --eos_id=2             --unk_id=3 --model_prefix=spm_ko --vocab_size=20000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus_ko.txt\n",
      "  input_format: \n",
      "  model_prefix: spm_ko\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus_ko.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78968 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5053323\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1211\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78967 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 160943 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78967\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 197024\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 197024 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=84459 obj=12.6252 num_tokens=381761 num_tokens/piece=4.52007\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=71553 obj=11.4805 num_tokens=383103 num_tokens/piece=5.35412\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=53656 obj=11.4865 num_tokens=400244 num_tokens/piece=7.45945\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=53630 obj=11.453 num_tokens=400594 num_tokens/piece=7.46959\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=40222 obj=11.598 num_tokens=424449 num_tokens/piece=10.5527\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=40221 obj=11.5632 num_tokens=424462 num_tokens/piece=10.5532\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=30165 obj=11.7552 num_tokens=451198 num_tokens/piece=14.9577\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=30165 obj=11.7135 num_tokens=451196 num_tokens/piece=14.9576\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22623 obj=11.9522 num_tokens=477939 num_tokens/piece=21.1262\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22623 obj=11.9061 num_tokens=477937 num_tokens/piece=21.1262\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22000 obj=11.9376 num_tokens=480429 num_tokens/piece=21.8377\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22000 obj=11.9325 num_tokens=480471 num_tokens/piece=21.8396\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spm_ko.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spm_ko.vocab\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=corpus_en.txt --pad_id=0 --bos_id=1 --eos_id=2             --unk_id=3 --model_prefix=spm_en --vocab_size=20000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus_en.txt\n",
      "  input_format: \n",
      "  model_prefix: spm_en\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus_en.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78968 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=10661485\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9663% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=52\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999663\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78956 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 91267 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78956\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 51464\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 51464 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=39940 obj=10.2203 num_tokens=97034 num_tokens/piece=2.42949\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=30470 obj=8.35681 num_tokens=97814 num_tokens/piece=3.21017\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22847 obj=8.28367 num_tokens=102709 num_tokens/piece=4.49551\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22826 obj=8.25959 num_tokens=102859 num_tokens/piece=4.50622\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21999 obj=8.25999 num_tokens=103827 num_tokens/piece=4.71962\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21994 obj=8.25778 num_tokens=103894 num_tokens/piece=4.72374\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spm_en.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spm_en.vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
    "def generate_tokenizer(corpus,\n",
    "                        vocab_size,\n",
    "                        lang=\"ko\",\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    temp_file = f'corpus_{lang}.txt'\n",
    "    \n",
    "    with open(temp_file, 'w') as f:\n",
    "        for row in corpus:\n",
    "            f.write(str(row) + '\\n')\n",
    "\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f'--input={temp_file} --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} \\\n",
    "            --unk_id={unk_id} --model_prefix=spm_{lang} --vocab_size={vocab_size}'\n",
    "    )\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load(f'spm_{lang}.model')\n",
    "\n",
    "    return tokenizer\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair.split(\"\\t\")\n",
    "\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d2197e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2e21ad3be54e59b1cf20c7330fe47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
    "for idx in tqdm(range(len(kor_corpus))):\n",
    "    src = ko_tokenizer.EncodeAsIds(kor_corpus[idx])\n",
    "    tgt = en_tokenizer.EncodeAsIds(eng_corpus[idx])\n",
    "    \n",
    "    if len(src) <= 50 and len(tgt) <= 50:\n",
    "        src_corpus.append(src)\n",
    "        tgt_corpus.append(tgt)\n",
    "\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성합니다. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4104fd7",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81509b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f7485b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "            \n",
    "        self.depth = d_model // self.num_heads\n",
    "            \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "            \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "            \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "        \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "            \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "                \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "097da037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea60e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98090b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff80a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41841f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0977b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4a0e200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch, length = 16, 20\n",
    "src_padding = 5\n",
    "tgt_padding = 15\n",
    "\n",
    "src_pad = tf.zeros(shape=(batch, src_padding))\n",
    "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
    "\n",
    "sample_data = tf.ones(shape=(batch, length))\n",
    "\n",
    "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
    "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
    "\n",
    "enc_mask, dec_enc_mask, dec_mask = \\\n",
    "generate_masks(sample_src, sample_tgt)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title('1) Encoder Mask')\n",
    "ax2.set_title('2) Encoder-Decoder Mask')\n",
    "ax3.set_title('3) Decoder Mask')\n",
    "\n",
    "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
    "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
    "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434a8b0",
   "metadata": {},
   "source": [
    "## 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1378f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=SRC_VOCAB_SIZE,\n",
    "    tgt_vocab_size=TGT_VOCAB_SIZE,\n",
    "    pos_len=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9d6e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "738a6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc873bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dc88ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86628999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a357e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 및 Attention 시각화 결합\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ae509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/4140373604.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(idx_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba629ead0bc848878a9ebd38fcd3de3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, ko_tokenizer, en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e61a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
