{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169ed241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/aiffel/aiffel/transformer_chatbot/data/ChatbotData .csv': File exists\r\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "# !ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1c241",
   "metadata": {},
   "source": [
    "# 0. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fb2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800373c2",
   "metadata": {},
   "source": [
    "# 1. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f65eb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_csv = pd.read_csv('./ChatbotData.csv')\n",
    "QA_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a222faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    \n",
    "    # 즉, vocab을 만들기 위한 전처리 과정 혹은 tokenizing 방식에 따라서는 필요함\n",
    "    # 현재는 subwordtokenizer를 사용하기에 필요함.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9가-힣ㄱ-ㅎㅏ-ㅣ.?!,]\", ' ', sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31646b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "    QA_csv.drop_duplicates(subset=['Q'],inplace=True)\n",
    "    QA_csv.drop_duplicates(subset=['A'],inplace=True)\n",
    "    inputs = QA_csv['Q'].apply(preprocess_sentence)\n",
    "    outputs = QA_csv['A'].apply(preprocess_sentence)\n",
    "  \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a9dea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7731 7731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         12시 땡 !\n",
       "1     1지망 학교 떨어졌어\n",
       "2    3박4일 놀러가고 싶다\n",
       "4         ppl 심하네\n",
       "5       sd카드 망가졌어\n",
       "Name: Q, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, outputs = load_conversations()\n",
    "print(len(inputs), len(outputs))\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52022138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(list(inputs) + list(outputs), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03191dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "# 원래 있던 단어를 지우고 Start_Token과 End_Token을 부여하는 것.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6793dd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [7775]\n",
      "END_TOKEN의 번호 : [7776]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa078a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7777\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea3ae2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가족들이랑 서먹해'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.iloc[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e02c0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [3782, 1096, 147, 544, 32]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [1575, 6637, 5845, 7551, 71, 2772, 767, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(inputs.iloc[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(outputs.iloc[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "053483b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 12\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93c126d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f55217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 7777\n",
      "필터링 후의 질문 샘플 개수: 6899\n",
      "필터링 후의 답변 샘플 개수: 6899\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(inputs, outputs)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92107ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cec01",
   "metadata": {},
   "source": [
    "# Transformer Architecture"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a996923b",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc80e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "    \n",
    "    def get_angles(self, position, index, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (index // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 일단 전체 index에 대해서 Positional Encoding 값을 다 생성함 \n",
    "        angle_rads = self.get_angles(\n",
    "            position= tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            index   = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model = d_model\n",
    "        )\n",
    "        \n",
    "        # 배열의 짝수 인덱스에는 sin 함수 사용함\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수를 적용함\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        # sin과 cosine이 교차되도록 재배열함.\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0])\n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef56b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81c91ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad1b7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length) \n",
    "  # 값이 곳에서만 1 나머지는 0으로 하는 Vector 생성\n",
    "  # 최후에는 해당 값과 element wise multiplication 연산을 진행해서 Masking을 진행함.\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42c23773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    \n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "691be259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1103c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de04ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5668638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ace3bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ceff360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3045120     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3572480     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7777)   1998689     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,616,289\n",
      "Trainable params: 8,616,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c56881",
   "metadata": {},
   "source": [
    "## Define Loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7aa236ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589e9bd",
   "metadata": {},
   "source": [
    "## Define Custom Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "624335c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818a8ca",
   "metadata": {},
   "source": [
    "## Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43d0ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0a4b6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75c6e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - 9s 30ms/step - loss: 5.2271 - accuracy: 0.0730\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 4.6588 - accuracy: 0.1621\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 4.0711 - accuracy: 0.1765\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 3.6410 - accuracy: 0.1778\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 3.3971 - accuracy: 0.1816\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 3.2518 - accuracy: 0.1892\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 3.1232 - accuracy: 0.1970\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 3.0004 - accuracy: 0.2032\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 2.8702 - accuracy: 0.2117\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 2.7306 - accuracy: 0.2216\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 2.5759 - accuracy: 0.2361\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 2.4079 - accuracy: 0.2525\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 2.2210 - accuracy: 0.2713\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 2.0273 - accuracy: 0.2926\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 1.8241 - accuracy: 0.3166\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 1.6087 - accuracy: 0.3459\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 1.3969 - accuracy: 0.3750\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 1.1825 - accuracy: 0.4102\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.9687 - accuracy: 0.4471\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.7700 - accuracy: 0.4857\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.5856 - accuracy: 0.5226\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.4267 - accuracy: 0.5533\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.3018 - accuracy: 0.5732\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.2102 - accuracy: 0.5863\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.1546 - accuracy: 0.5914\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.1235 - accuracy: 0.5932\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.1003 - accuracy: 0.5949\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - 3s 31ms/step - loss: 0.0889 - accuracy: 0.5955\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0826 - accuracy: 0.5956\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0755 - accuracy: 0.5966\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0726 - accuracy: 0.5960\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0722 - accuracy: 0.5956\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0701 - accuracy: 0.5953\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0688 - accuracy: 0.5956\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - 3s 31ms/step - loss: 0.0679 - accuracy: 0.5961\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0645 - accuracy: 0.5963\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - 3s 31ms/step - loss: 0.0657 - accuracy: 0.5955\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0658 - accuracy: 0.5956\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0567 - accuracy: 0.5981\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0536 - accuracy: 0.5989\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0482 - accuracy: 0.6000\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0485 - accuracy: 0.5997\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0440 - accuracy: 0.6009\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0383 - accuracy: 0.6029\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0383 - accuracy: 0.6022\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0359 - accuracy: 0.6026\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0312 - accuracy: 0.6035\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0295 - accuracy: 0.6046\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0271 - accuracy: 0.6052\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0255 - accuracy: 0.6055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f025c6800a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5bb008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29757d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a243167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 가만 있어도 땀난다\n",
      "출력 : 땀을 식혀주세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'땀을 식혀주세요 .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('가만 있어도 땀난다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19044845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
